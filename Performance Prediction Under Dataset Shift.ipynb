{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Prediction Under Dataset Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of different types of Performance Predictors under dataset shift.\n",
    "\n",
    "Results of paper \"Performance Prediction Under Dataset Shift\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from drift_dac_experiments.viz_utils import name2type\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "        'adult',\n",
    "        'video_games',\n",
    "        'heart',\n",
    "        'bank',\n",
    "        'dont_get_kicked',\n",
    "        'Churn_Modelling',\n",
    "        'bng_zoo',\n",
    "        'jsbach_chorals_modified',\n",
    "        'SDSS',\n",
    "        'bng_ionosphere',\n",
    "        'network_intrusion_detection',\n",
    "        'artificial_characters',\n",
    "        'default_of_credit_card_clients'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['dataset', 'ref. accuracy', 'CI'])\n",
    "df_test_no_shift = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "df_test_unseen = pd.DataFrame()\n",
    "df_test_unseen_subpop = pd.DataFrame()\n",
    "df_test_natural = pd.DataFrame()\n",
    "\n",
    "sets = ['train', 'test', 'test_no_shift', 'test_unseen', 'test_unseen_subpop', 'test_natural']\n",
    "\n",
    "for i, ds in enumerate(datasets):\n",
    "    \n",
    "    data_fld = ds + '_data'\n",
    "    pp_fld = ds + '_pp'\n",
    "    \n",
    "    print(data_fld.upper())\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        all_ref_accuracies = []\n",
    "        all_ci_drops = []\n",
    "        for seed in range(10):\n",
    "            with open(os.path.join(data_fld, './data_%d.pkl' % seed), 'rb') as f:\n",
    "                train, test, test_unseen, test_natural, ref_task, _ = pickle.load(f)\n",
    "\n",
    "            with open(os.path.join(data_fld, './shifts_%d.pkl' % seed), 'rb') as f:\n",
    "                list_of_drift_types, filtered_list_of_train_shifts, filtered_list_of_test_shifts, filtered_list_of_unseen_shifts = pickle.load(f)\n",
    "\n",
    "            train_shifts_names = [name2type(s) for s in filtered_list_of_train_shifts]\n",
    "            test_shifts_names = [name2type(s) for s in filtered_list_of_test_shifts]\n",
    "\n",
    "            ref_accuracy = ref_task.ref_accuracy\n",
    "\n",
    "            alpha = 0.05\n",
    "            n_samples = ref_task.y_src.shape[0]\n",
    "            sigma = np.sqrt(ref_accuracy * (1 - ref_accuracy) / n_samples)\n",
    "            ci_drop = stats.norm.ppf(1 - alpha / 2) * sigma\n",
    "\n",
    "            all_ref_accuracies.append(ref_accuracy)\n",
    "            all_ci_drops.append(ci_drop)\n",
    "\n",
    "\n",
    "        new_row = {\n",
    "         \"dataset\": data_fld,\n",
    "         \"ref. accuracy\": '%.3f \\tiny{$\\pm$%.3f}' % (np.mean(all_ref_accuracies), np.std(all_ref_accuracies)),\n",
    "         \"CI\": '%.3f \\tiny{$\\pm$%.3f}' % (np.mean(all_ci_drops), np.std(all_ci_drops))\n",
    "          }\n",
    "        df = df.append(new_row, ignore_index=True)\n",
    "        \n",
    "        with open(os.path.join(pp_fld, './model_names.npy'), 'rb') as f:\n",
    "            model_names = np.load(f)\n",
    "\n",
    "        for j, s in enumerate(sets):\n",
    "\n",
    "            with open(os.path.join(pp_fld, './r2_score_%s.npy'%s), 'rb') as f:\n",
    "                r2_score = np.load(f)\n",
    "\n",
    "            with open(os.path.join(pp_fld, './within_ci_mae_%s.npy'%s), 'rb') as f:\n",
    "                within_ci_mae = np.load(f)\n",
    "\n",
    "            with open(os.path.join(pp_fld, './likelihood_%s.npy'%s), 'rb') as f:\n",
    "                likelihood = np.load(f)\n",
    "\n",
    "            for i, name in enumerate(model_names):\n",
    "                new_row = {\"dataset\": ds, 'model': name}\n",
    "\n",
    "                new_row['mae_within_ci'] = '%.3f \\tiny{$\\pm$ %.3f}' % (np.mean(within_ci_mae[:, i]), np.std(within_ci_mae[:, i]))\n",
    "\n",
    "                if s=='test':\n",
    "                    df_test = df_test.append(new_row, ignore_index=True)\n",
    "                elif s=='test_no_shift':\n",
    "                    df_test_no_shift = df_test_no_shift.append(new_row, ignore_index=True)\n",
    "                elif s=='test_unseen':\n",
    "                    df_test_unseen = df_test_unseen.append(new_row, ignore_index=True)\n",
    "                elif s=='test_unseen_subpop':\n",
    "                    df_test_unseen_subpop = df_test_unseen_subpop.append(new_row, ignore_index=True)\n",
    "                elif s=='test_natural':\n",
    "                    df_test_natural = df_test_natural.append(new_row, ignore_index=True)\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"SKIP\")\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame with datasets accuracies and confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.to_latex(index=False).replace('textbackslash ','').replace('\\$','$').replace('\\{','{').replace('\\}', '}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame with MAE_CI_0.05 results for test_no_shift for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models = ['ATC', 'ExpertRF (amazon)', 'ExpertRF (naver)', 'ErrorPredictorRF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = df_test_no_shift[df_test_no_shift['model'].isin(selected_models)].set_index(['dataset', 'model']).stack().unstack([1,2])\n",
    "d = d[selected_models]\n",
    "d = d.iloc[d.index.str.lower().argsort()]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(d.to_latex().replace('textbackslash ','').replace('\\$','$').replace('\\{','{').replace('\\}', '}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame with MAE_CI_0.05 results for test_unseen_severity for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = df_test[df_test['model'].isin(selected_models)].set_index(['dataset', 'model']).stack().unstack([1,2])\n",
    "d = d[selected_models]\n",
    "d = d.iloc[d.index.str.lower().argsort()]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(d.to_latex().replace('textbackslash ','').replace('\\$','$').replace('\\{','{').replace('\\}', '}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame with MAE_CI_0.05 results for test_unseen_perturbation_shift for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = df_test_unseen[df_test_unseen['model'].isin(selected_models)].set_index(['dataset', 'model']).stack().unstack([1,2])\n",
    "d = d[selected_models]\n",
    "d = d.iloc[d.index.str.lower().argsort()]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(d.to_latex().replace('textbackslash ','').replace('\\$','$').replace('\\{','{').replace('\\}', '}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame with MAE_CI_0.05 results for test_unseen_subpop_shift for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = df_test_unseen_subpop[df_test_unseen_subpop['model'].isin(selected_models)].set_index(['dataset', 'model']).stack().unstack([1,2])\n",
    "d = d[selected_models]\n",
    "d = d.iloc[d.index.str.lower().argsort()]\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(d.to_latex().replace('textbackslash ','').replace('\\$','$').replace('\\{','{').replace('\\}', '}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame with MAE_CI_0.05 results for test_natural for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = df_test_natural[df_test_natural['model'].isin(selected_models)].set_index(['dataset', 'model']).stack().unstack([1,2])\n",
    "d = d[selected_models]\n",
    "d = d.iloc[d.index.str.lower().argsort()]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(d.to_latex().replace('textbackslash ','').replace('\\$','$').replace('\\{','{').replace('\\}', '}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all results plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = ['paper2', 'errpred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, ds in enumerate(datasets):\n",
    "    \n",
    "    data_fld = ds + '_data'\n",
    "    viz_fld = ds + '_viz'\n",
    "    \n",
    "    print(ds.upper())\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        plt.figure(figsize = figsize)\n",
    "        x = plt.imread(os.path.join(data_fld, 'true_drops_by_type_0.png'))\n",
    "        plt.imshow(x)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        for suffix in suffixes:\n",
    "            print('---- ' + ds + ' - ' + suffix)\n",
    "\n",
    "            plt.figure(figsize = figsize)\n",
    "            x = plt.imread(os.path.join(viz_fld, 'abs_error_' + suffix + '.png'))\n",
    "            plt.imshow(x)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize = figsize)\n",
    "            x = plt.imread(os.path.join(viz_fld, 'within_ci_mae_' + suffix + '.png'))\n",
    "            plt.imshow(x)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize = figsize)\n",
    "            x = plt.imread(os.path.join(viz_fld, 'likelihood_' + suffix + '.png'))\n",
    "            plt.imshow(x)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "creator": "smaggio",
  "customFields": {},
  "kernelspec": {
   "display_name": "Python (env drift_dac_exp)",
   "language": "python",
   "name": "py-dku-venv-drift_dac_exp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
